first we will set the environment for our proect 
so write a command for it  "conda create -p ./venv python=3.11 -y

"
and then activate the environment by writing the "conda activate ./venv
"
to check use python --version or pip list

if what to connect with git use "git init" then create a readme file

how want to add this file to git repo use "git add README.md  if there is some error like user change or owner change run this command "git config --global --add safe.directory 'D:/data science tut/MLProject'

and then run this git add README.md

use second one "git commit -m "first commit""get the ' 1 file changed, 1 insertion(+)
create mode 100644 README.md ''  output

git status use for check the status  

add on git repository we use git commads that is given during hte creation    

git branch -M main
git remote add origin https://github.com/adityaranu37/MLProject.git
git push -u origin main          //push the data

run all three individually 

you get some authoirization permission after that it will seet on your github
before if ask for email id and user you have to give with some command that is given on the git 
 

create the git ignore on the git by jjust write after the mlproect/__________ and select language


use git pull to updation of created file

creating the setup.py file so that the proect is createdd in package so that u can use it download it 

what we have done til yet is 
1.set up git  hub repository
a.new environment
b.requirements.txt
c.setup.py

2.src folder and build the packages   to add on git use git add .
check the status git status  
commit it   git commit -m "Add setup.py, requirements.txt, and src/__init__.py"

to push the main branch use   git push -u origin main


create the component folder and make the files init data ingestion data transformation

we will also create the pipline folder what types of pipline we need 
mainly two use training and prediction pipline and init.py as wee

now create the three main folder
for login
exception
utils.py // funcationlity that i am probaly writing in a comman way which wil use in entire application
like  to read the dataset from data base,  create the mongodbclient, to save the model into the clients


we will do work of data ingestion so that we can transform the data
after data ingestion aftifacs will created on executing the data ignestion file 

and then upload to git hub


now we will do dATA TRANSFORMATION
after this we willl work for model trainer.py and past some code to utilpy evalute function

here in artifacts model preocessor pkl file and catboost_info created on running the programm




 when we use hyper parameter then there is generation of value which taeks time to execute
 we can use hyper parameter after model tranier
 then use perfrom hyper parameter training  tuning to get best model



 now we are creating the pipeline using flask web app  
 creating the web application for interaction with these data pkl files  
 we have a form   where have  all input  data  that help to predict student performance and that data capture data


 create the app.py  import pkl flask

 we will use predict pipeline 
  while we create the app.py 
  and templates where index and home html will created
  

  now after that all set we will run and take output


  after that we will deployment it on the git hub


  we need to configuration to deployment of the project that is elastic bin stalk   create .ebextension and python.config  this is  mainly to tell elastic bin stock instance saying that entry point of the application

  create the application.py file which is same as app.py copy its to code to application fro only deployment purpose